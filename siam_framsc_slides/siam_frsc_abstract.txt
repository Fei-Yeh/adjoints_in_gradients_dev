Title: Application of Adjoint Operators in Gradient Computations
Author: James Folberth
University: University of Colorado at Boulder
Advisor: Stephen Becker

When using first-order optimization algorithms, it is often the case that the
user must supply the gradient of the differentiable terms in the objective
function.  We consider two example problems that have a Euclidean error term
involving a linear operation on the problem variables.  The gradient of the
Euclidean error term involves both the linear operator and its adjoint, which,
in our examples, is not known in the literature.  The first example is an
image deblurring problem, where the linear operation is multi-stage wavelet
synthesis.  Our formulation of the adjoint holds for a variety of boundary
conditions, which allows the formulation to generalize to a larger class of
problems.  The second example is a blind channel estimation problem taken from
the convex optimization literature; the linear operation is convolution, but
with a slight twist.  In each example, we show how the adjoint operator can be
applied efficiently.

